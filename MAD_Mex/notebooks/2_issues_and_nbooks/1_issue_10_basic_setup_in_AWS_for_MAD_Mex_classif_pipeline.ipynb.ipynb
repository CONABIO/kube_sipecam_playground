{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will solve:\n",
    "\n",
    "https://github.com/CONABIO/kube_sipecam_playground/issues/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up minikube and usage of docker image for MAD-Mex + kale in AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will follow: \n",
    "\n",
    "* For minikube: [minikube_sipecam/setup](https://github.com/CONABIO/kube_sipecam/tree/master/minikube_sipecam/setup#aws)\n",
    "\n",
    "* docker image for MAD-Mex: [kube_sipecam/dockerfiles/MAD_Mex/odc_kale](https://github.com/CONABIO/kube_sipecam/tree/master/dockerfiles/MAD_Mex/odc_kale) and [minikube_sipecam/deployments/MAD_Mex](https://github.com/CONABIO/kube_sipecam/tree/master/minikube_sipecam/deployments/MAD_Mex/)\n",
    "\n",
    "* Reference for this nbook: [1_issue_5_basic_setup_in_AWS_for_MAD_Mex_classif_pipeline](https://github.com/CONABIO/kube_sipecam_playground/blob/master/MAD_Mex/notebooks/1_issue_5_basic_setup_in_AWS_for_MAD_Mex_classif_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use [minikube_sipecam/deployments/MAD_Mex/hostpath_pv](https://github.com/CONABIO/kube_sipecam/tree/master/minikube_sipecam/deployments/MAD_Mex/hostpath_pv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance\n",
    "\n",
    "In AWS we can select ami: `k8s-1.16-debian-buster-amd64-hvm-ebs-2020-04-27 - ami-0ab39819e336a3f3f` and instance `m5.2xlarge` with `100` gb of disk.\n",
    "\n",
    "Use next bash script for user data to install `kubectl`, download `minikube` and `kfctl`:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next bash script works when only lc classification of MAD-Mex will be done**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "##variables:\n",
    "region=us-west-2\n",
    "user=admin\n",
    "name_instance=minikube\n",
    "shared_volume=/shared_volume\n",
    "##System update\n",
    "export DEBIAN_FRONTEND=noninteractive\n",
    "apt-get update -yq\n",
    "##Install awscli\n",
    "apt-get install -y python3-pip && pip3 install --upgrade pip\n",
    "pip3 install awscli --upgrade\n",
    "##Tag instance\n",
    "INSTANCE_ID=$(curl -s http://instance-data/latest/meta-data/instance-id)\n",
    "PUBLIC_IP=$(curl -s http://instance-data/latest/meta-data/public-ipv4)\n",
    "aws ec2 create-tags --resources $INSTANCE_ID --tag Key=Name,Value=$name_instance-$PUBLIC_IP --region=$region\n",
    "#check if locales are ok with next lines:\n",
    "echo \"export LC_ALL=C.UTF-8\" >> /root/.profile\n",
    "echo \"export LANG=C.UTF-8\" >> /root/.profile\n",
    "echo \"export mount_point=$shared_volume\" >> /root/.profile\n",
    "systemctl start docker\n",
    "usermod -aG docker $user\n",
    "newgrp docker\n",
    "#Create shared volume\n",
    "mkdir $shared_volume\n",
    "#kubectl installation\n",
    "curl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\"\n",
    "chmod +x ./kubectl\n",
    "mv ./kubectl /usr/local/bin/kubectl\n",
    "kubectl version --client\n",
    "#bash completion, needs to exit and enter again to take effect\n",
    "#echo \"source <(kubectl completion bash)\" >> /root/.bashrc\n",
    "#apt-get install -y bash-completion\n",
    "#minikube download\n",
    "curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\\n",
    "  && chmod +x minikube\n",
    "cp minikube /usr/local/bin/\n",
    "install minikube /usr/local/bin/\n",
    "apt-get install conntrack -y\n",
    "#kfctl download\n",
    "cd /root && wget https://github.com/kubeflow/kfctl/releases/download/v1.0.2/kfctl_v1.0.2-0-ga476281_linux.tar.gz\n",
    "tar -xvf kfctl_v1.0.2-0-ga476281_linux.tar.gz\n",
    "echo \"export PATH=$PATH:$(pwd)\" >> /root/.profile\n",
    "# Set KF_NAME to the name of your Kubeflow deployment. This also becomes the\n",
    "# name of the directory containing your configuration.\n",
    "# For example, your deployment name can be 'my-kubeflow' or 'kf-test'.\n",
    "echo \"export KF_NAME=kf-test\" >> ~/.profile\n",
    "echo \"export BASE_DIR=/opt\" >> ~/.profile\n",
    "source ~/.profile\n",
    "echo \"export KF_DIR=${BASE_DIR}/${KF_NAME}\" >> ~/.profile\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next bash script works when both land cover classification and upload layer to geonode will be done. Port 1111 was chosen arbitrarly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "##variables:\n",
    "region=us-west-2\n",
    "user=admin\n",
    "name_instance=minikube-07-09-2020\n",
    "shared_volume=/shared_volume\n",
    "##System update\n",
    "export DEBIAN_FRONTEND=noninteractive\n",
    "apt-get update -yq\n",
    "##Install awscli\n",
    "apt-get install -y python3-pip && pip3 install --upgrade pip\n",
    "pip3 install awscli --upgrade\n",
    "##Tag instance\n",
    "INSTANCE_ID=$(curl -s http://instance-data/latest/meta-data/instance-id)\n",
    "PUBLIC_IP=$(curl -s http://instance-data/latest/meta-data/public-ipv4)\n",
    "aws ec2 create-tags --resources $INSTANCE_ID --tag Key=Name,Value=$name_instance-$PUBLIC_IP --region=$region\n",
    "#check if locales are ok with next lines:\n",
    "echo \"export LC_ALL=C.UTF-8\" >> /root/.profile\n",
    "echo \"export LANG=C.UTF-8\" >> /root/.profile\n",
    "echo \"export mount_point=$shared_volume\" >> /root/.profile\n",
    "mkdir -p /etc/systemd/system/docker.service.d\n",
    "echo -e '[Service]\\nExecStart=\\nExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock -H tcp://0.0.0.0:1111' > /etc/systemd/system/docker.service.d/override.conf\n",
    "systemctl start docker\n",
    "usermod -aG docker $user\n",
    "newgrp docker\n",
    "#Create shared volume\n",
    "mkdir $shared_volume\n",
    "#kubectl installation\n",
    "curl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\"\n",
    "chmod +x ./kubectl\n",
    "mv ./kubectl /usr/local/bin/kubectl\n",
    "kubectl version --client\n",
    "#bash completion, needs to exit and enter again to take effect\n",
    "#echo \"source <(kubectl completion bash)\" >> /root/.bashrc\n",
    "#apt-get install -y bash-completion\n",
    "#minikube download\n",
    "curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\\n",
    "  && chmod +x minikube\n",
    "cp minikube /usr/local/bin/\n",
    "install minikube /usr/local/bin/\n",
    "apt-get install conntrack -y\n",
    "#kfctl download\n",
    "cd /root && wget https://github.com/kubeflow/kfctl/releases/download/v1.0.2/kfctl_v1.0.2-0-ga476281_linux.tar.gz\n",
    "tar -xvf kfctl_v1.0.2-0-ga476281_linux.tar.gz\n",
    "echo \"export PATH=$PATH:$(pwd)\" >> /root/.profile\n",
    "# Set KF_NAME to the name of your Kubeflow deployment. This also becomes the\n",
    "# name of the directory containing your configuration.\n",
    "# For example, your deployment name can be 'my-kubeflow' or 'kf-test'.\n",
    "echo \"export KF_NAME=kf-test\" >> ~/.profile\n",
    "echo \"export BASE_DIR=/opt\" >> ~/.profile\n",
    "source ~/.profile\n",
    "echo \"export KF_DIR=${BASE_DIR}/${KF_NAME}\" >> ~/.profile\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check installation in AWS instance with: `tail -n 15  /var/log/cloud-init-output.log`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ssh to instance, all commands will be executed as `root`**\n",
    "\n",
    "```\n",
    "sudo su\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next will install, start `minikube` using `none` driver and install `kfctl`:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CONFIG_URI=\"https://raw.githubusercontent.com/kubeflow/manifests/v1.0-branch/kfdef/kfctl_k8s_istio.v1.0.2.yaml\"\n",
    "source ~/.profile\n",
    "chmod gou+wrx -R /opt/\n",
    "mkdir -p ${KF_DIR}\n",
    "#minikube start\n",
    "cd /root && minikube start --driver=none\n",
    "#kubeflow start\n",
    "cd ${KF_DIR}\n",
    "\n",
    "wget $CONFIG_URI\n",
    "wget https://codeload.github.com/kubeflow/manifests/tar.gz/v1.0.2 -O v1.0.2.tar.gz\n",
    "\n",
    "```\n",
    "\n",
    "change kfctl_k8s_istio.v1.0.2.yaml at the end uri:\n",
    "\n",
    "```\n",
    "#this section:\n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: https://github.com/kubeflow/manifests/archive/v1.0.2.tar.gz\n",
    "#for: \n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: file:///opt/kf-test/v1.0.2.tar.gz\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "kfctl apply -V -f kfctl_k8s_istio.v1.0.2.yaml\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check pods and status with:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`minikube status`\n",
    "\n",
    "```\n",
    "minikube\n",
    "type: Control Plane\n",
    "host: Running\n",
    "kubelet: Running\n",
    "apiserver: Running\n",
    "kubeconfig: Configured\n",
    "```\n",
    "\n",
    "`kubectl get pods -n kubeflow`\n",
    "\n",
    "```\n",
    "#all running except:\n",
    "spark-operatorcrd-cleanup-2p7x2                                0/2     Completed   0          7m6s\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To access kubeflow UI set:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "export INGRESS_HOST=$(minikube ip)\n",
    "export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==\"http2\")].nodePort}')\n",
    "echo $INGRESS_PORT\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:$INGRESS_PORT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments and services \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "MAD_MEX_LOAD_BALANCER_SERVICE=loadbalancer-mad-mex-0.1.0_1.7.0_0.5.0-hostpath-pv\n",
    "MAD_MEX_PV=hostpath-pv\n",
    "MAD_MEX_PVC=hostpath-pvc\n",
    "MAD_MEX_JUPYTERLAB_SERVICE=jupyterlab-mad-mex-0.1.0_1.7.0_0.5.0-hostpath-pv\n",
    "MAD_MEX_URL=https://raw.githubusercontent.com/CONABIO/kube_sipecam/master/minikube_sipecam/deployments/MAD_Mex/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create storage:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl create -f $MAD_MEX_URL/hostpath_pv/$MAD_MEX_PV.yaml\n",
    "kubectl create -f $MAD_MEX_URL/hostpath_pv/$MAD_MEX_PVC.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create service:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl create -f $MAD_MEX_URL/hostpath_pv/$MAD_MEX_LOAD_BALANCER_SERVICE.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create deployment:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl create -f $MAD_MEX_URL/hostpath_pv/$MAD_MEX_JUPYTERLAB_SERVICE.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:30001/madmexurl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up postgresql instance in AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will follow:\n",
    "\n",
    "https://github.com/CONABIO/antares3-docker/tree/master/postgresql/local_deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clone, init DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /shared_volume\n",
    "dir=/shared_volume/postgresql_volume_docker\n",
    "mkdir $dir\n",
    "\n",
    "git clone https://github.com/CONABIO/antares3-docker.git $dir/antares3-docker\n",
    "\n",
    "mkdir -p $dir/etc/postgresql\n",
    "mkdir -p $dir/var/log/postgresql\n",
    "mkdir -p $dir/var/lib/postgresql\n",
    "\n",
    "docker run -v $dir/etc/postgresql:/etc/postgresql \\\n",
    "-v $dir/var/log/postgresql:/var/log/postgresql \\\n",
    "-v $dir/var/lib/postgresql:/var/lib/postgresql \\\n",
    "-v $dir/antares3-docker/postgresql/local_deployment/conf/:/home/postgres/conf/ \\\n",
    "-w /home/postgres \\\n",
    "-p 2225:22 -p 2345:5432 --name postgresql-madmex-odc --hostname postgresql-madmex \\\n",
    "-dit madmex/postgresql-madmex-local:v8 /bin/bash\n",
    "\n",
    "docker exec -it postgresql-madmex-odc /usr/local/bin/entrypoint.sh\n",
    "docker exec -u=postgres -it postgresql-madmex-odc /home/postgres/conf/setup.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `/shared_volume/.geonode_conabio`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "HOST_NAME=\"<ipv4 DNS of ec2>\"\n",
    "USER_GEOSERVER=\"super\"\n",
    "PASSWORD_GEOSERVER=\"duper\"\n",
    "PASSWORD_DB_GEONODE_DATA=\"geonode\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init files for antares3 and ODC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next commands in jupyterlab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`~/.datacube.conf`\n",
    "\n",
    "```\n",
    "[user]\n",
    "default_environment: datacube\n",
    "#default_environment: s3aio_env\n",
    "\n",
    "[datacube]\n",
    "db_hostname: 172.17.0.1\n",
    "db_database: antares_datacube\n",
    "db_username: postgres\n",
    "db_password: postgres\n",
    "db_port: 2345\n",
    "\n",
    "\n",
    "execution_engine.use_s3: False\n",
    "\n",
    "[s3aio_env]\n",
    "db_hostname: 172.17.0.1\n",
    "db_database: antares_datacube\n",
    "db_username: postgres\n",
    "db_password: postgres\n",
    "db_port: 2345\n",
    "\n",
    "#index_driver: s3aio_index\n",
    "\n",
    "execution_engine.use_s3: False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`~/.antares`\n",
    "\n",
    "```\n",
    "# Django settings\n",
    "SECRET_KEY=<key>\n",
    "DEBUG=True\n",
    "DJANGO_LOG_LEVEL=DEBUG\n",
    "ALLOWED_HOSTS=\n",
    "# Database\n",
    "DATABASE_NAME=antares_datacube\n",
    "DATABASE_USER=postgres\n",
    "DATABASE_PASSWORD=postgres\n",
    "DATABASE_HOST=172.17.0.1\n",
    "DATABASE_PORT=2345\n",
    "# Datacube\n",
    "SERIALIZED_OBJECTS_DIR=/shared_volume/datacube_ingest/serialized_objects/\n",
    "INGESTION_PATH=/shared_volume/datacube_ingest\n",
    "#DRIVER=s3aio\n",
    "DRIVER='NetCDF CF'\n",
    "#INGESTION_BUCKET=datacube-s2-jalisco-test\n",
    "# Query and download\n",
    "USGS_USER=<username>\n",
    "USGS_PASSWORD=<password>\n",
    "SCIHUB_USER=\n",
    "SCIHUB_PASSWORD=\n",
    "# Misc\n",
    "BIS_LICENSE=<license>\n",
    "TEMP_DIR=/shared_volume/temp\n",
    "SEGMENTATION_DIR=/shared_volume/segmentation/\n",
    "#SEGMENTATION_BUCKET=<name of bucket>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create dir for segmentation if will hold results of that process:**\n",
    "\n",
    "`mkdir /shared_volume/segmentation/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upgrade antares with no deps:**\n",
    "\n",
    "`pip3 install --user git+https://github.com/CONABIO/antares3.git@develop --upgrade --no-deps`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Init antares and datacube:**\n",
    "\n",
    "```\n",
    "~/.local/bin/antares init\n",
    "datacube -v system init\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create spatial indexes:**\n",
    "\n",
    "```\n",
    "apt-get install -y postgresql-client\n",
    "psql -h 172.17.0.1 -d antares_datacube -U postgres -p 2345\n",
    "#password postgres\n",
    "CREATE INDEX madmex_predictobject_gix ON public.madmex_predictobject USING GIST (the_geom);\n",
    "CREATE INDEX madmex_trainobject_gix ON public.madmex_trainobject USING GIST (the_geom);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**\n",
    "\n",
    "`datacube -v system check`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are some notes that could be followed [Notes](https://github.com/CONABIO/antares3-docker/tree/master/postgresql/local_deployment#note) for docker container of postgresql**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register and ingest LANDSAT 8 data into ODC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 bucket that has data: `landsat-images-kube-sipecam-mad-mex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare metadata:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "~/.local/bin/antares prepare_metadata --path \"/\" --bucket landsat-images-kube-sipecam-mad-mex --dataset_name landsat_espa --outfile /shared_volume/metadata_mex_l8.yaml --multi 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datacube ingestion:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "datacube -v product add ~/.config/madmex/indexing/ls8_espa_scenes.yaml\n",
    "datacube -v dataset add /shared_volume/metadata_mex_l8.yaml\n",
    "datacube -v ingest -c ~/.config/madmex/ingestion/ls8_espa_mexico.yaml --executor multiproc 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register and ingest SRTM data into ODC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using https://conabio.github.io/antares3/example_s2_land_cover.html#prepare-terrain-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From http://dwtkns.com/srtm/ will download srtm data for Chiapas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /shared_volume\n",
    "wget http://srtm.csi.cgiar.org/wp-content/uploads/files/srtm_5x5/tiff/srtm_18_09.zip\n",
    "apt-get install -y unzip\n",
    "unzip srtm_18_09.zip -d /shared_volume/srtm_18_09\n",
    "mkdir /shared_volume/srtm_mosaic\n",
    "cp /shared_volume/srtm_18_09/srtm_18_09.tif /shared_volume/srtm_mosaic/srtm_mosaic.tif\n",
    "gdaldem slope /shared_volume/srtm_mosaic/srtm_mosaic.tif /shared_volume/srtm_mosaic/slope_mosaic.tif -s 111120\n",
    "gdaldem aspect /shared_volume/srtm_mosaic/srtm_mosaic.tif /shared_volume/srtm_mosaic/aspect_mosaic.tif\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create product and Index mosaic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`datacube -v product add ~/.config/madmex/indexing/srtm_cgiar.yaml`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "~/.local/bin/antares prepare_metadata --path /shared_volume/srtm_mosaic --dataset_name srtm_cgiar --outfile /shared_volume/metadata_srtm.yaml\n",
    "\n",
    "datacube -v dataset add /shared_volume/metadata_srtm.yaml\n",
    "datacube -v ingest -c ~/.config/madmex/ingestion/srtm_cgiar_mexico.yaml --executor multiproc 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Mexico's shapefile to antares-datacube DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`~/.local/bin/antares init -c 'MEX'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest training data in antares-datacube DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training data is in bucket `training-data-kube-sipecam-mad-mex`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "~/.local/bin/antares ingest_training_from_vector /shared_volume/training_data/Chiapas_31.shp --scheme madmex --year 2015 --name train_chiapas_dummy --field class\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "If disk is full which could happen if a kubeflow pipeline will be uploaded from kale:\n",
    "\n",
    "```\n",
    "HTTP response headers: HTTPHeaderDict({'Date': 'Tue, 01 Sep 2020 18:12:22 GMT', 'Content-Length': '487', 'Content-Type': 'text/plain; charset=utf-8'})\n",
    "HTTP response body: {\"error_message\":\"Error creating pipeline: Create pipeline failed: InternalServerError: Failed to store b2fa5a70-cab4-4c89-8784-9c0cb118d1b4: Storage backend has reached its minimum free disk threshold. Please delete a few objects to proceed.\",\"error_details\":\"Error creating pipeline: Create pipeline failed: InternalServerError: Failed to store b2fa5a70-cab4-4c89-8784-9c0cb118d1b4: Storage backend has reached its minimum free disk threshold. Please delete a few objects to proceed.\"}\n",
    "```\n",
    "\n",
    "Delete kubeflow (MAD-Mex and geonode deployments)\n",
    "\n",
    "To free space:\n",
    "\n",
    "```\n",
    "minikube stop\n",
    "minikube delete\n",
    "```\n",
    "\n",
    "Check:\n",
    "\n",
    "```\n",
    "docker system df\n",
    "docker system prune --all --volumes\n",
    "rm -r /root/.minikube/*\n",
    "rm -r /root/.kube/*\n",
    "rm -r /opt/kf-test\n",
    "```\n",
    "\n",
    "Start again (being in root dir):\n",
    "\n",
    "```\n",
    "CONFIG_URI=\"https://raw.githubusercontent.com/kubeflow/manifests/v1.0-branch/kfdef/kfctl_k8s_istio.v1.0.2.yaml\"\n",
    "source ~/.profile\n",
    "chmod gou+wrx -R /opt/\n",
    "mkdir -p ${KF_DIR}\n",
    "#minikube start\n",
    "cd /root && minikube start --driver=none\n",
    "#kubeflow start\n",
    "cd ${KF_DIR}\n",
    "\n",
    "wget $CONFIG_URI\n",
    "wget https://codeload.github.com/kubeflow/manifests/tar.gz/v1.0.2 -O v1.0.2.tar.gz\n",
    "\n",
    "```\n",
    "\n",
    "change kfctl_k8s_istio.v1.0.2.yaml at the end uri:\n",
    "\n",
    "```\n",
    "#this section:\n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: https://github.com/kubeflow/manifests/archive/v1.0.2.tar.gz\n",
    "#for: \n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: file:///opt/kf-test/v1.0.2.tar.gz\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "kfctl apply -V -f kfctl_k8s_istio.v1.0.2.yaml\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "ref: https://github.com/aws-samples/eks-workshop/issues/639\n",
    "\n",
    "If there's problems with geonode (because stack of docker-compose was deleted, clone again repo and deploy geonode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
