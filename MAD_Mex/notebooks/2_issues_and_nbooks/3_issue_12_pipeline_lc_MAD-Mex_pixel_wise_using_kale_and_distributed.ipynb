{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example of recipe computation, model fit, predict* and conversion to raster using [distributed](http://distributed.dask.org/en/latest/), API of antares3 and [kale](https://github.com/kubeflow-kale/kale) functionality\n",
    "\n",
    "*Prediction is pixel wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Will use an already ingested and processed Landsat8 data via antares3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "import dill\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from affine import Affine\n",
    "from dask.distributed import Client\n",
    "from rasterio.features import rasterize\n",
    "import datacube\n",
    "from datacube.api import GridWorkflow\n",
    "from datacube.storage import masking\n",
    "from datacube.drivers.netcdf import write_dataset_to_netcdf\n",
    "\n",
    "from madmex.util.db import get_cmap_from_scheme\n",
    "from madmex.models import Tag\n",
    "from madmex.overlay.extractions import zonal_stats_xarray\n",
    "from madmex.io.vector_db import VectorDb\n",
    "from madmex.wrappers import gwf_query\n",
    "from madmex.modeling.supervised.xgb import Model\n",
    "from madmex.models import Tag\n",
    "from madmex.overlay.extractions import zonal_stats_xarray\n",
    "from madmex.util import randomword, mid_date, join_dicts\n",
    "from madmex.util.xarray import to_float, to_int\n",
    "from django.contrib.gis.geos.geometry import GEOSGeometry\n",
    "from madmex.models import PredictObject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recipe computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def recipe_computation(tile):\n",
    "    crs = tile[1][0].geobox.crs\n",
    "\n",
    "    ds = xr.combine_by_coords([GridWorkflow.load(x, dask_chunks={'x': 1200, 'y': 1200})\n",
    "                                 for x in tile[1]], data_vars='minimal', coords='minimal')\n",
    "    ds.attrs['geobox'] = tile[1][0].geobox\n",
    "    \n",
    "    # Mask clouds, shadow, water, ice,... and drop qa layer\n",
    "    clear = masking.make_mask(ds.pixel_qa, cloud=False, cloud_shadow=False,\n",
    "                              snow=False)\n",
    "    ds_1 = ds.where(clear)\n",
    "    ds_1 = ds_1.drop('pixel_qa')\n",
    "    ds_1 = ds_1.apply(func=to_float, keep_attrs=True)\n",
    "    # Compute vegetation indices\n",
    "    ds_1['ndvi'] = ((ds_1.nir - ds_1.red) / (ds_1.nir + ds_1.red)) * 10000\n",
    "    ds_1['ndvi'].attrs['nodata'] = -9999\n",
    "    ds_1['ndmi'] = ((ds_1.nir - ds_1.swir1) / (ds_1.nir + ds_1.swir1)) * 10000\n",
    "    ds_1['ndmi'].attrs['nodata'] = -9999\n",
    "    # Run temporal reductions and rename DataArrays\n",
    "    ds_mean = ds_1.mean('time', keep_attrs=True, skipna=True)\n",
    "    ds_mean = ds_mean.rename({'blue': 'blue_mean',\n",
    "                              'green': 'green_mean',\n",
    "                              'red': 'red_mean',\n",
    "                              'nir': 'nir_mean',\n",
    "                              'swir1': 'swir1_mean',\n",
    "                              'swir2': 'swir2_mean',\n",
    "                              'ndmi': 'ndmi_mean',\n",
    "                              'ndvi': 'ndvi_mean'})\n",
    "    # Compute min/max/std only for vegetation indices\n",
    "    ndvi_max = ds_1.ndvi.max('time', keep_attrs=True, skipna=True)\n",
    "    ndvi_max = ndvi_max.rename('ndvi_max')\n",
    "    ndvi_max.attrs['nodata'] = -9999\n",
    "    ndvi_min = ds_1.ndvi.min('time', keep_attrs=True, skipna=True)\n",
    "    ndvi_min = ndvi_min.rename('ndvi_min')\n",
    "    ndvi_min.attrs['nodata'] = -9999\n",
    "    # ndmi\n",
    "    ndmi_max = ds_1.ndmi.max('time', keep_attrs=True, skipna=True)\n",
    "    ndmi_max = ndmi_max.rename('ndmi_max')\n",
    "    ndmi_max.attrs['nodata'] = -9999\n",
    "    ndmi_min = ds_1.ndmi.min('time', keep_attrs=True, skipna=True)\n",
    "    ndmi_min = ndmi_min.rename('ndmi_min')\n",
    "    ndmi_min.attrs['nodata'] = -9999\n",
    "    # Load terrain metrics using same spatial parameters than sr\n",
    "    dc = datacube.Datacube(app = 'landsat_madmex_003_%s' % randomword(5))\n",
    "    terrain = dc.load(product='srtm_cgiar_mexico', like=ds,\n",
    "                      time=(datetime(1970, 1, 1), datetime(2018, 1, 1)),\n",
    "                      dask_chunks={'x': 1200, 'y': 1200})\n",
    "    dc.close()\n",
    "    # Merge dataarrays\n",
    "    combined = xr.merge([ds_mean.apply(to_int),\n",
    "                         to_int(ndvi_max),\n",
    "                         to_int(ndvi_min),\n",
    "                         to_int(ndmi_max),\n",
    "                         to_int(ndmi_min),\n",
    "                         terrain])\n",
    "    combined.attrs['crs'] = crs\n",
    "    #write_dataset_to_netcdf(combined.compute(scheduler='threads'), nc_filename)\n",
    "    return (tile[0], combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Following [landsat_madmex_003.py](https://github.com/CONABIO/antares3/blob/develop/madmex/recipes/landsat_madmex_003.py)\n",
    "\n",
    "Also could be helpful:\n",
    "\n",
    "[1c_clusterization_for_agriculture_inecol](https://github.com/CONABIO/antares3-sandbox/blob/master/notebooks/agriculture_madmex_app/1c_clusterization_for_agriculture_inecol.ipynb)\n",
    "\n",
    "\n",
    "[1d_clusterization_for_agriculture_inecol](https://github.com/CONABIO/antares3-sandbox/blob/master/notebooks/agriculture_madmex_app/1d_clusterization_for_agriculture_inecol.ipynb)\n",
    "\n",
    "[2_clusterization_for_agriculture_inecol_intersect_with_area_of_interest.](https://github.com/CONABIO/antares3-sandbox/blob/master/notebooks/agriculture_madmex_app/2_clusterization_for_agriculture_inecol_intersect_with_area_of_interest.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "block:gwf_query"
    ]
   },
   "outputs": [],
   "source": [
    "os.environ.setdefault(\"DJANGO_ALLOW_ASYNC_UNSAFE\", \"true\")\n",
    "\n",
    "region = 'Chiapas'\n",
    "products = ['ls8_espa_mexico']\n",
    "begin = '2017-01-01'\n",
    "end = '2017-12-31'\n",
    "gwf_kwargs = {'region': region, \n",
    "              'begin': begin, \n",
    "              'end':end}  \n",
    "#query\n",
    "\n",
    "dict_list = []\n",
    "for prod in products:\n",
    "    gwf_kwargs.update(product = prod)\n",
    "    try:\n",
    "        dict_list.append(gwf_query(**gwf_kwargs, view=False))\n",
    "    # Exception is in case one of the product hasn't been registered in the datacube\n",
    "    except Exception as e:\n",
    "        pass\n",
    "iterable = join_dicts(*dict_list, join='full').items()\n",
    "\n",
    "\n",
    "list_iter = list(iterable)\n",
    "\n",
    "list_iter_sorted = sorted(list_iter, key = lambda x: (x[0][0], x[0][1]))\n",
    "\n",
    "list_iter_sorted = list_iter_sorted[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "print(list_iter_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:recipe_computation_parallel",
     "prev:gwf_query"
    ]
   },
   "outputs": [],
   "source": [
    "os.environ.setdefault(\"DJANGO_ALLOW_ASYNC_UNSAFE\", \"true\")\n",
    "futures_recipe = Client(n_workers=2,memory_limit='15GB', threads_per_worker=1).map(recipe_computation, list_iter_sorted, pure=False)\n",
    "results_recipe = [future.result() for future in futures_recipe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def model_fit(tup, training_data, path_result):\n",
    "    tile, combined = tup\n",
    "    loader = VectorDb()\n",
    "    fc_train_0 = loader.load_training_from_dataset(dataset=combined,\n",
    "                                                   training_set=training_data, \n",
    "                                                   sample=1)\n",
    "    \n",
    "    fc_train_0 = list(fc_train_0)\n",
    "    \n",
    "    \n",
    "    #Assign code level to this training data according to next scheme...\n",
    "    scheme = \"madmex\"\n",
    "    \n",
    "    qs = Tag.objects.filter(scheme=scheme)\n",
    "    tag_mapping = {x.id:x.numeric_code for x in qs}\n",
    "    tag_id_list = [x['properties']['class'] for x in fc_train_0]\n",
    "    \n",
    "    fc_train = [{'geometry': x[0]['geometry'],\n",
    "                 'properties': {'code': tag_mapping[x[1]]},\n",
    "                 'type': 'feature'} for x in zip(fc_train_0, tag_id_list)]\n",
    "    X_train, y_train = zonal_stats_xarray(combined, fc_train, 'code')\n",
    "\n",
    "    xgb_model = Model()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    #filename_model = 'model_landsat8_chiapas_2017_madmex_31_clases_via_kale' + '_%d_%d' %(tile[0],tile[1]) + '.pkl'\n",
    "    #filepath_model = os.path.join(path_result, filename_model)\n",
    "    #with open(filepath_model, 'wb') as dst:\n",
    "    #    dill.dump(xgb_model, dst)\n",
    "    return (tile, xgb_model, combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:model_fit_parallel",
     "prev:recipe_computation_parallel"
    ]
   },
   "outputs": [],
   "source": [
    "os.environ.setdefault(\"DJANGO_ALLOW_ASYNC_UNSAFE\", \"true\")\n",
    "training_data = \"train_chiapas_dummy\"\n",
    "#path_result = \"/shared_volume/land_cover_results_parallel\"\n",
    "#if not os.path.exists(path_result):\n",
    "#    os.makedirs(path_result)\n",
    "futures_model_fit = Client(n_workers=2,memory_limit='15GB', threads_per_worker=1).map(model_fit, results_recipe,\n",
    "                                                                                      **{'training_data': training_data,\n",
    "                                                                                         'path_result': path_result})\n",
    "results_model_fit = [future.result() for future in futures_model_fit]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict and write raster to FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def predict_and_write_raster(tup, path_result):\n",
    "    tile, xgb_model, combined = tup\n",
    "    arr_3d = combined.to_array().squeeze().values #squeeze to remove time dimension \n",
    "                                        #because has length 1\n",
    "    arr_3d = np.moveaxis(arr_3d, 0, 2)\n",
    "    \n",
    "    shape_2d = (arr_3d.shape[0] * arr_3d.shape[1], arr_3d.shape[2])\n",
    "    \n",
    "    arr_2d = arr_3d.reshape(shape_2d)\n",
    "    \n",
    "    predicted_array = xgb_model.predict(arr_2d)\n",
    "    \n",
    "    #write to FS\n",
    "    \n",
    "    predicted_array = predicted_array.reshape((arr_3d.shape[0], arr_3d.shape[1]))\n",
    "    predicted_array = predicted_array.astype('uint8')\n",
    "    \n",
    "    rasterio_meta = {'width': predicted_array.shape[1],\n",
    "                     'height': predicted_array.shape[0],\n",
    "                     'transform': ds.affine,\n",
    "                     'crs': ds.crs.crs_str,\n",
    "                     'count': 1,\n",
    "                     'dtype': 'uint8',\n",
    "                     'compress': 'lzw',\n",
    "                     'driver': 'GTiff',\n",
    "                     'nodata': 0}\n",
    "    \n",
    "    filename_raster = 'raster_landsat8_chiapas_madmex_31_clases_pixel_wise_via_kale' + '_%d_%d' %(tile[0],tile[0]) + '.tif'\n",
    "    filename_raster = os.path.join(path_result, filename_raster)\n",
    "    \n",
    "    with rasterio.open(filename_raster, 'w', **rasterio_meta) as dst:\n",
    "        dst.write(predicted_array, indexes = 1)\n",
    "    return filename_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:predict_write_raster_parallel",
     "prev:model_fit_parallel"
    ]
   },
   "outputs": [],
   "source": [
    "os.environ.setdefault(\"DJANGO_ALLOW_ASYNC_UNSAFE\", \"true\")\n",
    "training_data = \"train_chiapas_dummy\"\n",
    "path_result = \"/shared_volume/land_cover_results_parallel\"\n",
    "if not os.path.exists(path_result):\n",
    "    os.makedirs(path_result)\n",
    "futures_predict_and_write_raster = Client(n_workers=2,memory_limit='15GB', threads_per_worker=1).map(predict_and_write_raster, \n",
    "                                                                                                     results_model_fit,\n",
    "                                                                                                     **{'path_result': path_result})\n",
    "results_predict_and_write_raster = [future.result() for future in futures_predict_and_write_raster]\n",
    "print(results_predict_and_write_raster)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "sipecam/madmex-odc-kale:0.1.0_1.7.0_0.5.0",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "pipeline_description": "MAD-Mex parallel land cover pixel wise",
   "pipeline_name": "madmex-parallel-lc",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/shared_volume",
     "name": "hostpath-pvc",
     "size": 1,
     "size_type": "Gi",
     "snapshot": false,
     "snapshot_name": "",
     "type": "pvc"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
