{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dir=/shared_volume/\n",
    "#dir=/LUSTRE/MADMEX/tasks/2021/pyei_pipeline\n",
    "\n",
    "mkdir $dir/pyei_data\n",
    "\n",
    "wget -O $dir/pyei_data/dropbox_data.zip https://www.dropbox.com/sh/alab97y1fimlzoe/AADcNaR-Y66IfelP0nqnN0Bca?dl=1\n",
    "\n",
    "sudo apt-get install unzip\n",
    "\n",
    "unzip $dir/pyei_data/dropbox_data.zip -d $dir/pyei_data/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must use 16gb for docker container [sipecam/madmex-kale:0.5.0_0.1.0](https://github.com/CONABIO/kube_sipecam/blob/master/minikube_sipecam/deployments/MAD_Mex/jupyterlab-mad-mex-0.5.0_0.1.0.yaml#L19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import os\n",
    "import ntpath\n",
    "import numpy as np\n",
    "import fiona\n",
    "import rasterio\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import gc\n",
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import GA_ReadOnly \n",
    "from osgeo.gdalconst import GDT_Float32\n",
    "from osgeo.gdalconst import GDT_Int16\n",
    "from osgeo.gdalconst import GDT_UInt16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#direc = \"/LUSTRE/MADMEX/tasks/2021/pyei_pipeline\"\n",
    "direc = \"/shared_volume\"\n",
    "data_path = os.path.join(direc,\"pyei_data\", \"1_strucdiv\")\n",
    "infys_shapefile = os.path.join(direc,\"pyei_data\", \"1_strucdiv\", \"1.1_strucdiv_infys.shp\")\n",
    "train_data_dir = os.path.join(direc, \"pyei_train_data\")\n",
    "train_file = \"1.1_train_table.csv\"\n",
    "pyei_results_dir = os.path.join(direc, \"pyei_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of files with a certain ending.\n",
    "# Search is recursive and traverses all (sub)folders.\n",
    "def list_files(directory, endswith=\".tif\"):\n",
    "    files_endswith = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(endswith):\n",
    "                fullpath = root + '/' + file\n",
    "                files_endswith.append(fullpath)\n",
    "    return files_endswith\n",
    "\n",
    "# Obtain point coordinates from a point feature in a shapefile.\n",
    "def coords(point):\n",
    "    x = point[\"geometry\"][\"coordinates\"][0]\n",
    "    y = point[\"geometry\"][\"coordinates\"][1]\n",
    "\n",
    "    return {\"coordinates\" : (x, y)}\n",
    "\n",
    "# Obtain the data associated to a variable of a shapefile.\n",
    "def values(points, variable):\n",
    "    npoints = len(points)\n",
    "    nvalues = np.zeros(npoints)\n",
    "    i=0\n",
    "    for point in points:\n",
    "        val = point[\"properties\"][variable]\n",
    "        nvalues[i] = val\n",
    "        i += 1\n",
    "    return(nvalues)\n",
    "\n",
    "\n",
    "# Given a shapefile read with fiona extract raster values.\n",
    "def extract(points, raster):\n",
    "\n",
    "    npoints = len(points)\n",
    "    ex_values = np.zeros(npoints)\n",
    "    i=0\n",
    "    with rasterio.open(raster) as src:\n",
    "        for point in points:\n",
    "            for value in src.sample([coords(point)[\"coordinates\"]]):\n",
    "                ex_values[i] = value\n",
    "                i += 1\n",
    "    return ex_values\n",
    "\n",
    "\n",
    "# From a pair (spatial_sampling_points, raster_variable_list)\n",
    "# Create a traininig table for model building.\n",
    "# First column is considered the dependent variable.\n",
    "def create_trainset(points, file_list, variable):\n",
    "\n",
    "    trainset = np.empty((len(points), len(file_list) + 1))\n",
    "    vals = values(points = points, variable = variable)\n",
    "    trainset[:,0] = values(points = points, variable = variable)\n",
    "\n",
    "    i=1\n",
    "    for file in file_list: \n",
    "        trainset[:,i] = extract(points = points, raster = file)\n",
    "        i += 1 \n",
    "\n",
    "    return(trainset) \n",
    "\n",
    "# Get raster dimensions.\n",
    "def dims(raster):\n",
    "    with rasterio.open(raster, 'r') as ds:\n",
    "        raster = ds.read()\n",
    "\n",
    "    raster_dimensions = raster.shape    \n",
    "    x = raster_dimensions[1]\n",
    "    y = raster_dimensions[2]\n",
    "    return (x,y)\n",
    "\n",
    "# Given a raster file-list create a numpy array.\n",
    "# Each raster (variable) becomes a column.\n",
    "def rasters_to_table(file_list):\n",
    "\n",
    "    # Read in first raster to extract metadata.\n",
    "    xy = dims(file_list[0])\n",
    " \n",
    "    x = xy[0]\n",
    "    y = xy[1]\n",
    "\n",
    "    # Initialize numpy array to place raster bands.\n",
    "    ntable = np.zeros((x*y, len(file_list)))\n",
    "    i = 0\n",
    "    for raster in file_list:\n",
    "        with rasterio.open(raster, 'r') as ds:\n",
    "            ntable[:,i] = ds.read().flatten()\n",
    "            i += 1\n",
    "\n",
    "    return(ntable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_train_data = os.path.join(train_data_dir, train_file)\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(output_file_train_data):\n",
    "    \n",
    "    os.mkdir(train_data_dir)\n",
    "\n",
    "    geotiffs = list_files(data_path)\n",
    "    \n",
    "    shapef_source = os.path.join(data_path, infys_shapefile)\n",
    "    \n",
    "    shapef = fiona.open(shapef_source)\n",
    "    \n",
    "    train_table = create_trainset(shapef, geotiffs, \"AlturTtl_m\")\n",
    "    \n",
    "    np.savetxt(output_file_train_data, train_table, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5123075273950167\n"
     ]
    }
   ],
   "source": [
    "# Load training data array.\n",
    "data = np.loadtxt(output_file_train_data, delimiter=',')\n",
    "\n",
    "# Instantiate model with 1000 decision trees.\n",
    "# n_jobs is subject to available cores (8 cores in parallel in this case).\n",
    "model = RandomForestRegressor(n_estimators = 100, random_state = 42, oob_score = True, n_jobs = 8)\n",
    "\n",
    "# Train the model.\n",
    "model.fit(data[:,1:], data[:,0])\n",
    "\n",
    "# Out-Of-Bag estimation of correlatino between observed and predicted values.\n",
    "oob_corr = math.sqrt(model.oob_score_)\n",
    "print(oob_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the full data set (all of MX).\n",
    "geotiffs = list_files(data_path)\n",
    "\n",
    "rast = rasterio.open(geotiffs[0])\n",
    "\n",
    "rmetadata = rast.meta\n",
    "\n",
    "full_data = rasters_to_table(geotiffs)\n",
    "predictions = model.predict(full_data).astype(\"float32\")\n",
    "predictions = predictions.reshape((rmetadata[\"height\"], rmetadata[\"width\"]))\n",
    "\n",
    "predictions_file = os.path.join(pyei_results_dir, \"1.2_avg_tree_height.tif\")\n",
    "\n",
    "if not os.path.exists(pyei_results_dir):\n",
    "    os.mkdir(pyei_results_dir)\n",
    "with rasterio.open(predictions_file, 'w', **rmetadata) as dst:\n",
    "    dst.write(predictions, indexes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtif(imagepath):\n",
    "    gdal.AllRegister()\n",
    "    inDataset = gdal.Open(imagepath,GA_ReadOnly)\n",
    "    cols = inDataset.RasterXSize\n",
    "    rows = inDataset.RasterYSize\n",
    "    bands = inDataset.RasterCount\n",
    "    return(inDataset,rows,cols,bands)\n",
    "\n",
    "def createtif(driver,rows,cols,bands,outpath,data_type=32):\n",
    "    if data_type==32:\n",
    "        outDataset = driver.Create(outpath,cols,rows,bands,GDT_Float32,[ \"COMPRESS=LZW\" ])\n",
    "    elif data_type==16:\n",
    "        outDataset = driver.Create(outpath,cols,rows,bands,GDT_UInt16,[ \"COMPRESS=LZW\" ])\n",
    "    return(outDataset)\n",
    "\n",
    "def writetif(outDataset,data,projection,geotransform,order='r'):\n",
    "    # order controls if the columns or the rows should be considered the observations\n",
    "    cols = outDataset.RasterXSize \n",
    "    rows = outDataset.RasterYSize\n",
    "    if geotransform is not None:\n",
    "        gt = list(geotransform)\n",
    "        gt[0] = gt[0] + 0*gt[1]\n",
    "        gt[3] = gt[3] + 0*gt[5]\n",
    "        outDataset.SetGeoTransform(tuple(gt))\n",
    "    if projection is not None:\n",
    "        outDataset.SetProjection(projection)\n",
    "    \n",
    "    if data.ndim==1:\n",
    "        outBand = outDataset.GetRasterBand(1)\n",
    "        resized = np.reshape(data,(rows,cols))\n",
    "        outBand.WriteArray(resized,0,0)\n",
    "        outBand.FlushCache()\n",
    "    else:\n",
    "        if order=='r':\n",
    "            n=np.shape(data)[0]\n",
    "            for k in range(n):\n",
    "                outBand = outDataset.GetRasterBand(k+1)\n",
    "                outBand.WriteArray(np.resize(data[k,:],(rows,cols)),0,0)\n",
    "                outBand.FlushCache()\n",
    "        elif order=='c':\n",
    "            n=np.shape(data)[1]\n",
    "            for k in range(n):\n",
    "                outBand = outDataset.GetRasterBand(k+1)\n",
    "                outBand.WriteArray(np.reshape(data[:,k],(rows,cols)))\n",
    "                outBand.FlushCache()\n",
    "\n",
    "    #close the dataset properly\n",
    "    outDataset = None\n",
    "\n",
    "def swapValues(flattenedNumpyArray,listOfInLists,listOfSwappingValues):\n",
    "    '''\n",
    "    takes each list in tlistOfInLists and swaps it by the\n",
    "    corresponding value in listOfSwappingValues\n",
    "    '''\n",
    "    aux=flattenedNumpyArray\n",
    "    if len(listOfInLists)!=len(listOfSwappingValues):\n",
    "        print(\"Lists must be of the same length.\")\n",
    "    else:\n",
    "        for i in range(len(listOfInLists)):\n",
    "            # list to numpy array\n",
    "            nparray = np.array(listOfInLists[i])\n",
    "            found_idx = np.in1d(flattenedNumpyArray,nparray)\n",
    "            aux[found_idx]=listOfSwappingValues[i]\n",
    "    aux = aux.astype(int)\n",
    "    return(aux)\n",
    "def multispectralToBits(multispec_raster_path,class_ids, out_dir):\n",
    "    # Get data from raster with classifications\n",
    "    ds = gdal.Open(multispec_raster_path)\n",
    "    band = ds.GetRasterBand(1)\n",
    "    class_ar = band.ReadAsArray()\n",
    "    gt = ds.GetGeoTransform()\n",
    "    pj = ds.GetProjection()\n",
    "    ds = band = None  # close\n",
    "    \n",
    "    # Make a new bit rasters\n",
    "    drv = gdal.GetDriverByName(\"GTiff\")\n",
    "    bit_raster_file = os.path.join(pyei_results_dir, \"bit_raster.tif\")\n",
    "    ds = drv.Create(bit_raster_file, class_ar.shape[1], class_ar.shape[0],\n",
    "                    len(class_ids), gdal.GDT_Byte, [\"NBITS=1\"])\n",
    "    ds.SetGeoTransform(gt)\n",
    "    ds.SetProjection(pj)\n",
    "    for bidx in range(ds.RasterCount):\n",
    "        band = ds.GetRasterBand(bidx + 1)\n",
    "        # create boolean result where 0 == no and 1 == yes\n",
    "        selection = (class_ar == class_ids[bidx]).astype(\"u1\")\n",
    "        band.WriteArray(selection)\n",
    "    ds = band = None  # save, close\n",
    "    return bit_raster_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.UseExceptions()\n",
    "\n",
    "data_path = os.path.join(direc,\"pyei_data\",\"2_landcover\")\n",
    "in_raster = \"madmex_lcc_landsat_2018_v4.3.1_chp.tif\"\n",
    "out_raster = \"madmex_lcc_landsat_2018_v4.3.1_chp_7c.tif\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_raster_file = os.path.join(data_path, in_raster)\n",
    "dataset,rows,cols,bands = readtif(in_raster_file)\n",
    "\n",
    "# Image metadata.\n",
    "projection = dataset.GetProjection()\n",
    "transform = dataset.GetGeoTransform()\n",
    "driver = dataset.GetDriver()\n",
    "\n",
    "# make numpy array and flatten\n",
    "band = dataset.GetRasterBand(1)\n",
    "band = band.ReadAsArray(0, 0, cols, rows).astype(np.int16)\n",
    "band = np.ravel(band)\n",
    "\n",
    "# Remove missing values from class remapping.\n",
    "gooddata_idx = band != 0\n",
    "gooddata = band[gooddata_idx]\n",
    "\n",
    "# Raster with remapped classes.\n",
    "aggregated = swapValues(gooddata,[\\\n",
    "                                  [1,2,3,6],\\\n",
    "                                  [7,8, 9,10,11,12, 21, 22, 25, 26],\\\n",
    "                                  #[4,5, 13, 14, 15, 16, 17, 18, 19, 20],\\\n",
    "                                  [27, 28],\\\n",
    "                                  [23, 24, 30],\\\n",
    "                                  [29],\\\n",
    "                                  [31]\n",
    "                                 ],\\\n",
    "                        [1,2,4,5,6,7])\n",
    "\n",
    "# [1,2,3,8] \t\t\t\t\t\t  -to- 1 bosque\n",
    "# [9,10,11,12,13,14,15,16]    \t\t  -to- 2 selvas\n",
    "# [4,5,6,7,17,18,19,21,22,23, 25, 26] -to- 3 matorrales\n",
    "# [27, 28] \t\t\t\t\t\t\t  -to- 4 pastizal y agricultura \n",
    "# [30, 20, 24]  \t\t\t\t\t  -to- 5 suelo desnudo\n",
    "# [31]      \t\t\t\t\t\t  -to- 6 asentamiento humano\n",
    "# [29]      \t\t\t\t\t\t  -to- 7 agua\n",
    "# [98, 99]  \t\t\t\t\t\t  -to- 8 nieve y hielo\n",
    "\n",
    "band[gooddata_idx] = aggregated\n",
    "\n",
    "# Set up output and write.\n",
    "tif_out_file = os.path.join(pyei_results_dir, out_raster)\n",
    "if not os.path.exists(tif_out_file):\n",
    "    outData = createtif(driver, rows, cols, 1, tif_out_file,16)\n",
    "    writetif(outData,band, projection, transform)\n",
    "    outData = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_raster = \"madmex_lcc_landsat_2018_v4.3.1_chp_7c.tif\"\n",
    "out_raster = \"madmex_lcc_landsat_2018_v4.3.1_chp_7cprop.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open raster.\n",
    "class_ids=[1,2,4,5,6,7]\n",
    "\n",
    "data_to_bits_file = os.path.join(pyei_results_dir, in_raster)\n",
    "res_multispectraltobits = multispectralToBits(data_to_bits_file, class_ids, pyei_results_dir)\n",
    "\n",
    "src_ds = gdal.Open(res_multispectraltobits)\n",
    "\n",
    "# Open a template or copy array, for dimensions and NODATA mask.\n",
    "cpy_ds_file = os.path.join(pyei_results_dir, \"1.2_avg_tree_height.tif\")\n",
    "cpy_ds = gdal.Open(cpy_ds_file)\n",
    "band = cpy_ds.GetRasterBand(1)\n",
    "cpy_mask = (band.ReadAsArray() == band.GetNoDataValue())\n",
    "\n",
    "# Result raster, with same resolution and position as the copy raster.\n",
    "drv = gdal.GetDriverByName(\"GTiff\")\n",
    "\n",
    "#out_raster = \"madmex_lcc_landsat_2018_v4.3.1_chp_7c.tif\"\n",
    "\n",
    "dst_ds_file = os.path.join(pyei_results_dir, out_raster)\n",
    "\n",
    "if not os.path.exists(dst_ds_file):\n",
    "\n",
    "    dst_ds = drv.Create(dst_ds_file, cpy_ds.RasterXSize, cpy_ds.RasterYSize,\n",
    "                        len(class_ids), gdal.GDT_Float32, [\"INTERLEAVE=BAND\"])\n",
    "    dst_ds.SetGeoTransform(cpy_ds.GetGeoTransform())\n",
    "    dst_ds.SetProjection(cpy_ds.GetProjection())\n",
    "    \n",
    "    # Do the same as gdalwarp -r average; this might take a while to finish.\n",
    "    gdal.ReprojectImage(src_ds, dst_ds, None, None, gdal.GRA_Average)\n",
    "    \n",
    "    # Convert all fractions to percent, and apply the same NODATA mask from the copy raster.\n",
    "    NODATA = 0\n",
    "    for bidx in range(dst_ds.RasterCount):\n",
    "        band = dst_ds.GetRasterBand(bidx + 1)\n",
    "        ar = band.ReadAsArray() * 100.0\n",
    "        ar[cpy_mask] = NODATA\n",
    "        band.WriteArray(ar)\n",
    "        band.SetNoDataValue(NODATA)\n",
    "    \n",
    "    # Save and close all rasters\n",
    "    src_ds = cpy_ds = dst_ds = band = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
